name: Build AdGuardHome rules

on:
  schedule:
    - cron: "0 0 * * *"
    - cron: "0 6 * * *"
    - cron: "0 12 * * *"
    - cron: "0 18 * * *"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download & Merge Rules (Clean + Deduplicate)
        run: |
          mkdir -p dist tmp

          urls=(
            "https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/Create%20a%20Custom%20AdGuard%20Home%20Filtering%20Rule.txt"
            "https://raw.githubusercontent.com/BlueSkyXN/AdGuardHomeRules/master/skyrules.txt"
            "https://easylist-downloads.adblockplus.org/easylist.txt"
            "https://easylist-downloads.adblockplus.org/easylistchina.txt"
            "https://easylist-downloads.adblockplus.org/easyprivacy.txt"
            "https://raw.githubusercontent.com/banbendalao/ADgk/master/ADgk.txt"
            "https://raw.githubusercontent.com/banbendalao/ADgk/master/kill-baidu-ad.txt"
            "https://raw.githubusercontent.com/217heidai/adblockfilters/main/rules/adblockdnslite.txt"
            "https://raw.githubusercontent.com/REIJI007/Adblock-Rule-Collection/main/ADBLOCK_RULE_COLLECTION_DNS.txt"
            "https://anti-ad.net/easylist.txt"
            "https://gh-proxy.com/raw.githubusercontent.com/changzhaoCZ/fqnovel-adrules/refs/heads/main/fqnovel-fxxk_ads"
            "https://www.i-dont-care-about-cookies.eu/abp/"
          )

          echo "ðŸ“¥ ä¸‹è½½æ‰€æœ‰è§„åˆ™..."
          for url in "${urls[@]}"; do
            echo "Downloading $url"
            curl -sSL --retry 3 --fail "$url" >> tmp/all_raw.txt || echo "Failed $url"
            echo "" >> tmp/all_raw.txt
          done

          echo "ðŸ§¹ æ¸…ç†æ³¨é‡Šå’Œç©ºè¡Œ..."
          grep -vE '^[[:space:]]*[!#]' tmp/all_raw.txt | sed '/^[[:space:]]*$/d' > tmp/all_cleaned.txt

          echo "ðŸ“Š åŽ»é‡è§„åˆ™..."
          sort tmp/all_cleaned.txt | uniq > tmp/all_deduped_tmp.txt

          # âœ… åˆ†ç¦»ç™½åå•å’Œé˜»æ­¢è§„åˆ™
          grep '^@@||' tmp/all_deduped_tmp.txt > tmp/whitelist.txt
          grep -v '^@@||' tmp/all_deduped_tmp.txt > tmp/blocklist.txt

          # âœ… wxglenovo ç™½åå•ä¼˜å…ˆ
          curl -sSL --retry 3 --fail "https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/Create%20a%20Custom%20AdGuard%20Home%20Filtering%20Rule.txt" \
            | grep '^@@||' | sort | uniq > tmp/source_whitelist.txt

          # âœ… æœ€ç»ˆé¡ºåºï¼šwxglenovo ç™½åå• > å…¶ä»–ç™½åå• > é˜»æ­¢è§„åˆ™
          cat tmp/source_whitelist.txt tmp/whitelist.txt tmp/blocklist.txt | sort | uniq > tmp/all_deduped.txt

          RAW_COUNT=$(wc -l < tmp/all_cleaned.txt)
          DEDUP_COUNT=$(wc -l < tmp/all_deduped.txt)
          DUP_COUNT=$((RAW_COUNT - DEDUP_COUNT))
          WHITELIST_COUNT=$(grep -c '^@@||' tmp/all_deduped.txt)
          TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S %Z')
          WHITE_RATIO=$(awk "BEGIN {printf \"%.2f\", (${WHITELIST_COUNT}/${DEDUP_COUNT})*100}")

          # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
          {
            echo "åŽŸå§‹æ€»æ•°ï¼š$RAW_COUNT"
            echo "åŽ»é‡åŽï¼š$DEDUP_COUNT"
            echo "é‡å¤è¡Œæ•°ï¼š$DUP_COUNT"
            echo "ç™½åå•æ¡æ•°ï¼š$WHITELIST_COUNT"
            echo "ç™½åå•æ¯”ä¾‹ï¼š${WHITE_RATIO}%"
            echo "æ›´æ–°æ—¶é—´ï¼š$TIMESTAMP"
            echo "æ¥æºåˆ—è¡¨ï¼š${#urls[@]} ä¸ª"
          } | tee dist/old_rules.txt

          # âœ… ç”Ÿæˆ AdGuardHome.txtï¼ˆå¸¦ ! æ³¨é‡Šç»Ÿè®¡ä¿¡æ¯ï¼‰
          {
            echo "! æ›´æ–°æ—¶é—´ï¼š$TIMESTAMP"
            echo "! åŽŸå§‹è§„åˆ™æ•°ï¼š$RAW_COUNT"
            echo "! åŽ»é‡åŽè§„åˆ™æ•°ï¼š$DEDUP_COUNT"
            echo "! åŽ»é‡æ¡æ•°ï¼š$DUP_COUNT"
            echo "! ç™½åå•æ¡æ•°ï¼š$WHITELIST_COUNT"
            echo "! ç™½åå•æ¯”ä¾‹ï¼š${WHITE_RATIO}%"
            echo "! æ¥æºåˆ—è¡¨ï¼š${#urls[@]} ä¸ª"
            echo ""
            cat tmp/all_deduped.txt
          } > dist/AdGuardHome.txt

          echo "$DEDUP_COUNT" > dist/line_count.txt
