      - name: Build AdGuardHome Rules

          mkdir -p dist tmp
          > tmp/all_raw.txt

          urls=(
            "https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/main/AdGuard%20Home_Allowlist.txt"
            "https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/main/AdGuard%20Home_Blacklist.txt"
            "https://raw.githubusercontent.com/changzhaoCZ/fqnovel-adrules/main/fqnovel-fxxk_ads"
            "https://anti-ad.net/easylist.txt"
            "https://raw.githubusercontent.com/REIJI007/Adblock-Rule-Collection/main/ADBLOCK_RULE_COLLECTION_DNS.txt"
            "https://raw.githubusercontent.com/217heidai/adblockfilters/main/rules/adblockdnslite.txt"
            "https://raw.githubusercontent.com/banbendalao/ADgk/master/ADgk.txt"
            "https://easylist-downloads.adblockplus.org/easyprivacy.txt"
            "https://easylist-downloads.adblockplus.org/easylistchina.txt"
            "https://easylist-downloads.adblockplus.org/easylist.txt"
            "https://raw.githubusercontent.com/BlueSkyXN/AdGuardHomeRules/master/skyrules.txt"
            "https://raw.githubusercontent.com/cjx82630/cjxlist/master/cjx-annoyance.txt"
            "https://raw.githubusercontent.com/hagezi/dns-blocklists/main/adblock/light.txt"
            "https://raw.githubusercontent.com/wxglenovo/Shadowrocket-to-AdGuard-Home/main/AdGuardHome.txt"
          )

          echo "📥 开始下载并合并所有规则..."
          for url in "${urls[@]}"; do
            echo "Downloading $url"
            curl -sSL --retry 3 "$url" >> tmp/all_raw.txt || echo "⚠️ Failed to download $url, skipped" >> tmp/all_raw.txt
            echo "" >> tmp/all_raw.txt
          done

          echo "🧹 清理注释、空行，同时删除无用规则..."
          grep -vE '^[[:space:]]*[!#]' tmp/all_raw.txt \
            | grep -v '^\$' \
            | grep -v -E '%2Fevent.gif%3F|%2Fo.gif&|%2Fopen.aspx%3F|%2Frw%2Fbeacon_|&&sub19=undefined|&&sub20=undefined|&EventType=DataDealImpression|&EventType=Impression|&action=js_stats|&ad\*|&puid=\*|&uid=\*=show|&ad=\*|&referer=|&adb=y|&adid=|&cbiframe=|&cx=c&gtm=|&ep.analytics_storage=|&ev=PageView|&event_name=page_view|&event_name=view_item_list|&fp_sid=pop\$popup|&ga_blocked=|&hitType=pageview|&http_referer=|&l=dataLayer&cx=c|&pagegroup=|&url=|&popunder=|&popundersPerIP=|&rb=&uuid=|&refer=http|&sadbl=1|&chu=|&sseq=|&dseq=|&sst.sw_exp=|&subaffid=|&t=pageview|&xhtml\?|&zoneid=|*\$app=com.miui.systemAdSolution|\*-stats.jpush.cn\^|*.com/css/showfloatdiv\^|*/\?tzbilibili|*/ad\.|*/adbox/|*/adload\.|*/ads\.|*/adsense/|*/html/click/|*/mediaController|*/piaofu\.|*/piaofu/|*/redirect\?ad_cb=|*/svnad/|\*ContentAD\.|\*H5Logic_|-468x60_|-468x70\.|-468x80-\$image|-468x80\.|-468x80/|-468x80_|-468x90\.|-480x60-|-480x60\.|-480x60/|-480x60_|-486x60\.|-500x100\.|-600x70\.|-600x90-/' \
            | sed '/^[[:space:]]*$/d' > tmp/all_cleaned.txt

          echo "📊 去重并排序..."
          sort tmp/all_cleaned.txt | uniq > tmp/all_deduped_tmp.txt

          # ✅ wxglenovo 白名单靠前
          curl -sSL --retry 3 "https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/main/Create%20a%20Custom%20AdGuard%20Home%20Filtering%20Rule.txt" \
            | grep '^@@||' > tmp/source_whitelist.txt || echo "⚠️ Failed to download wxglenovo whitelist, skipped"

          grep '^@@||' tmp/all_deduped_tmp.txt > tmp/whitelist.txt
          grep -v '^@@||' tmp/all_deduped_tmp.txt > tmp/blocklist.txt

          cat tmp/source_whitelist.txt tmp/whitelist.txt tmp/blocklist.txt | uniq > tmp/all_deduped.txt

          TIMESTAMP=$(TZ='Asia/Shanghai' date '+%Y-%m-%d %H:%M:%S %Z')
          RAW_COUNT=$(wc -l < tmp/all_cleaned.txt)
          DEDUP_COUNT=$(wc -l < tmp/all_deduped.txt)
          DUP_COUNT=$((RAW_COUNT - DEDUP_COUNT))
          WHITELIST_COUNT=$(grep -c '^@@||' tmp/all_deduped.txt)
          WHITE_RATIO=$(awk "BEGIN {printf \"%.2f\", (${WHITELIST_COUNT}/${DEDUP_COUNT})*100}")

          echo "原始总数：$RAW_COUNT" | tee dist/old_rules.txt
          echo "去重后：$DEDUP_COUNT" | tee -a dist/old_rules.txt
          echo "重复行数：$DUP_COUNT" | tee -a dist/old_rules.txt
          echo "白名单条数：$WHITELIST_COUNT" | tee -a dist/old_rules.txt
          echo "白名单比例：${WHITE_RATIO}%" | tee -a dist/old_rules.txt
          echo "更新时间：$TIMESTAMP" | tee -a dist/old_rules.txt

          {
            echo "! ================================================================"
            echo "! 🧩 AdGuardHome 规则合并结果"
            echo "! 更新时间：$TIMESTAMP"
            echo "! 原始规则数：$RAW_COUNT"
            echo "! 去重后规则数：$DEDUP_COUNT"
            echo "! 去重条数：$DUP_COUNT"
            echo "! 白名单条数：$WHITELIST_COUNT"
            echo "! 白名单比例：${WHITE_RATIO}%"
            echo "! 来源列表：${#urls[@]} 个"
            echo "! ================================================================"
            echo ""
            cat tmp/all_deduped.txt
          } > dist/AdGuardHome.txt

          echo "$DEDUP_COUNT" > dist/line_count.txt
