name: Build AdGuardHome rules

on:
  schedule:
    - cron: "0 0 * * *"
    - cron: "0 6 * * *"
    - cron: "0 12 * * *"
    - cron: "0 18 * * *"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download & Merge Rules (Clean + Deduplicate)
        run: |
          set -e
          mkdir -p dist tmp

          urls=(
            "https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/AdGuard%20Home_Allowlist.txt"
            "https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/AdGuard%20Home_Blacklist.txt"
            "https://gh-proxy.com/raw.githubusercontent.com/changzhaoCZ/fqnovel-adrules/refs/heads/main/fqnovel-fxxk_ads"
            "https://www.i-dont-care-about-cookies.eu/abp/"
            "https://anti-ad.net/easylist.txt"
            "https://raw.githubusercontent.com/REIJI007/Adblock-Rule-Collection/main/ADBLOCK_RULE_COLLECTION_DNS.txt"
            "https://raw.githubusercontent.com/217heidai/adblockfilters/main/rules/adblockdnslite.txt"
            "https://raw.githubusercontent.com/banbendalao/ADgk/master/ADgk.txt"
            "https://easylist-downloads.adblockplus.org/easyprivacy.txt"
            "https://easylist-downloads.adblockplus.org/easylistchina.txt"
            "https://easylist-downloads.adblockplus.org/easylist.txt"
            "https://raw.githubusercontent.com/BlueSkyXN/AdGuardHomeRules/master/skyrules.txt"
            "https://raw.githubusercontent.com/cjx82630/cjxlist/master/cjx-annoyance.txt"
            "https://raw.githubusercontent.com/hagezi/dns-blocklists/main/adblock/light.txt"
            "https://raw.githubusercontent.com/wxglenovo/Shadowrocket-to-AdGuard-Home/refs/heads/main/AdGuardHome.txt"
          )

          echo "ğŸ“¥ å¼€å§‹ä¸‹è½½å¹¶åˆå¹¶æ‰€æœ‰è§„åˆ™..."
          rm -f tmp/all_raw.txt tmp/all_cleaned.txt tmp/all_deduped.txt
          for url in "${urls[@]}"; do
            echo "Downloading $url"
            curl -sSL --retry 3 --fail "$url" >> tmp/all_raw.txt || echo "Failed $url"
            echo "" >> tmp/all_raw.txt
          done

          echo "ğŸ§¹ æ¸…ç†æ³¨é‡Šå’Œç©ºè¡Œ..."
          grep -vE '^[[:space:]]*[!#]' tmp/all_raw.txt | sed '/^[[:space:]]*$/d' > tmp/all_cleaned.txt

          echo "ğŸ“Š å»é‡å¹¶æ’åº (LC_ALL=C sort -u)..."
          LC_ALL=C sort -u tmp/all_cleaned.txt > tmp/all_deduped.txt

          # åˆ†ç¦»ç™½åå•å’Œé»‘åå•
          grep '^@@||' tmp/all_deduped.txt | LC_ALL=C sort -t'.' -k2,2 -k1,1 > dist/whitelist.txt || true
          grep -v '^@@||' tmp/all_deduped.txt | LC_ALL=C sort -t'.' -k2,2 -k1,1 > dist/blocklist.txt || true

          # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
          TIMESTAMP=$(TZ='Asia/Shanghai' date '+%Y-%m-%d %H:%M:%S %Z')
          RAW_COUNT=$(wc -l < tmp/all_cleaned.txt)
          DEDUP_COUNT=$(wc -l < tmp/all_deduped.txt)
          DUP_COUNT=$((RAW_COUNT - DEDUP_COUNT))
          WHITELIST_COUNT=$(wc -l < dist/whitelist.txt)
          BLACKLIST_COUNT=$(wc -l < dist/blocklist.txt)
          WHITE_RATIO=$(awk "BEGIN {printf \"%.2f\", (${WHITELIST_COUNT}/${DEDUP_COUNT})*100}")

          echo "åŸå§‹æ€»æ•°ï¼š$RAW_COUNT" | tee dist/old_rules.txt
          echo "å»é‡åï¼š$DEDUP_COUNT" | tee -a dist/old_rules.txt
          echo "é‡å¤è¡Œæ•°ï¼š$DUP_COUNT" | tee -a dist/old_rules.txt
          echo "ç™½åå•æ¡æ•°ï¼š$WHITELIST_COUNT" | tee -a dist/old_rules.txt
          echo "é»‘åå•æ¡æ•°ï¼š$BLACKLIST_COUNT" | tee -a dist/old_rules.txt
          echo "ç™½åå•æ¯”ä¾‹ï¼š${WHITE_RATIO}%" | tee -a dist/old_rules.txt
          echo "æ›´æ–°æ—¶é—´ï¼š$TIMESTAMP" | tee -a dist/old_rules.txt

          echo "âœ… æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼Œdist/ç›®å½•æ–‡ä»¶åˆ—è¡¨:"
          ls -l dist/
          echo "å‰ 10 è¡Œ whitelist:"
          head -n 10 dist/whitelist.txt
          echo "å‰ 10 è¡Œ blocklist:"
          head -n 10 dist/blocklist.txt
