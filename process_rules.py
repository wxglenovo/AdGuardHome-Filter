import re
import requests
import os
from datetime import datetime, timedelta, timezone

# ===============================
# ğŸŒ ç™½åå•ä¸é»‘åå•åœ°å€
# ===============================
whitelist_url = 'https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/dist/whitelist.txt'
blocklist_url = 'https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/dist/blocklist.txt'

last_count_file = "last_count.txt"

# ===============================
# ğŸ“¥ è·å–è¿œç¨‹æ–‡ä»¶å¹¶æ¸…ç†æ— ç”¨è¡Œï¼ˆå»é™¤!å¼€å¤´çš„å¤´éƒ¨ä¿¡æ¯ï¼‰
# ===============================
def fetch_file(url):
    try:
        r = requests.get(url)
        r.raise_for_status()
        lines = []
        for line in r.text.splitlines():
            line = line.strip()
            if line and not line.startswith('!'):
                lines.append(line)
        return lines
    except requests.RequestException as e:
        print(f"è·å–æ–‡ä»¶å¤±è´¥: {e}")
        exit(1)

# è·å–ç™½åå•ä¸é»‘åå•è§„åˆ™
whitelist = fetch_file(whitelist_url)
blocklist = fetch_file(blocklist_url)

# ===============================
# ğŸ§© æå–ä¸»åŸŸå‡½æ•°ï¼ˆç”¨äºå»é™¤å­åŸŸï¼‰
# ===============================
def get_base_domain(domain):
    parts = domain.split('.')
    if len(parts) >= 2:
        return '.'.join(parts[-2:])
    return domain

# ===============================
# âš™ï¸ è§„åˆ™æ¸…ç†å‡½æ•°ï¼ˆåˆ é™¤å­åŸŸï¼‰
# ===============================
def process_rules(rules, allow_prefix="@@||", block_prefix="||"):
    seen = set()
    cleaned = []
    deleted_count = 0

    for line in rules:
        line = line.strip()
        if not line or line.startswith('#'):
            cleaned.append(line)
            continue

        # åŒ¹é…ç™½åå•æˆ–é»‘åå•è§„åˆ™
        if line.startswith(allow_prefix):
            prefix = allow_prefix
            body = line[len(allow_prefix):]
        elif line.startswith(block_prefix):
            prefix = block_prefix
            body = line[len(block_prefix):]
        else:
            cleaned.append(line)
            continue

        # æå–åŸŸåéƒ¨åˆ†ï¼ˆå»æ‰ ^ã€/ã€$ ä¹‹åçš„å†…å®¹ï¼‰
        domain = re.split(r'[\^/\$]', body)[0].strip()
        if not domain:
            cleaned.append(line)
            continue

        base = get_base_domain(domain)
        if base not in seen:
            seen.add(base)
            cleaned.append(line)
        else:
            deleted_count += 1

    return cleaned, deleted_count

# ===============================
# ğŸ§¹ åˆ†åˆ«å¤„ç†ç™½åå•ä¸é»‘åå•
# ===============================
cleaned_whitelist, deleted_whitelist = process_rules(whitelist, allow_prefix="@@||", block_prefix="||")
cleaned_blocklist, deleted_blocklist = process_rules(blocklist, allow_prefix="@@||", block_prefix="||")

# ===============================
# ğŸ“Š è¯»å–ä¸ä¿å­˜ä¸Šæ¬¡ç»Ÿè®¡æ•°é‡
# ===============================
def read_last_count():
    if os.path.exists(last_count_file):
        with open(last_count_file, 'r') as f:
            lines = f.read().splitlines()
            if len(lines) >= 2:
                return int(lines[0]), int(lines[1])
    return 0, 0

def write_current_count(w_count, b_count):
    with open(last_count_file, 'w') as f:
        f.write(f"{w_count}\n{b_count}\n")

current_w = len(cleaned_whitelist)
current_b = len(cleaned_blocklist)
last_w, last_b = read_last_count()
diff_w = current_w - last_w
diff_b = current_b - last_b

# ===============================
# ğŸ§¾ ç”Ÿæˆå¤´éƒ¨ä¿¡æ¯ï¼ˆåˆ†å¼€æ˜¾ç¤ºï¼‰
# ===============================
def generate_header(list_type, url, original_count, deleted_count, current_count, diff_count):
    # ä½¿ç”¨åŒ—äº¬æ—¶é—´ï¼ˆUTC+8ï¼‰
    beijing_time = datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')

    diff_str = (
        f"å¢åŠ  {diff_count} æ¡" if diff_count > 0 else
        f"å‡å°‘ {abs(diff_count)} æ¡" if diff_count < 0 else "æ— å˜åŒ– 0 æ¡"
    )

    header = f"""###########################################################
# ğŸ“… AdGuardHome {list_type} è‡ªåŠ¨æ„å»ºä¿¡æ¯
# â° æ›´æ–°æ—¶é—´: {beijing_time} CST
# ğŸŒ è§„åˆ™æ¥æº: {url}
# --------------------------------------------------------
# ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:
#   â–¸ åŸå§‹è§„åˆ™æ•°é‡: {original_count}
#   â–¸ åˆ é™¤å­åŸŸæ•°é‡: {deleted_count}
#   â–¸ æ¸…ç†åè§„åˆ™æ•°é‡: {current_count}
#   â–¸ ä¸ä¸Šæ¬¡å¯¹æ¯”: {diff_str}
# --------------------------------------------------------
# ğŸ§© è¯´æ˜:
#   å½“çˆ¶åŸŸä¸å­åŸŸï¼ˆåŒ…æ‹¬è§„åˆ™åç¼€ï¼‰åŒæ—¶å­˜åœ¨æ—¶ï¼Œä¿ç•™çˆ¶åŸŸè§„åˆ™ã€‚
#   å¤šçº§å­åŸŸï¼ˆä¸‰çº§ã€å››çº§ï¼‰åˆ™ä¿ç•™çº§æ•°æ›´ä½çš„åŸŸåï¼ˆçˆ¶åŸŸï¼‰ã€‚
# ==========================================================
"""
    return header

header_whitelist = generate_header(
    "ç™½åå•", whitelist_url, len(whitelist), deleted_whitelist, current_w, diff_w
)

header_blocklist = generate_header(
    "é»‘åå•", blocklist_url, len(blocklist), deleted_blocklist, current_b, diff_b
)

# ===============================
# ğŸ’¾ è¾“å‡ºä¸ºä¸¤ä¸ªæ–‡ä»¶
# ===============================
with open("cleaned_whitelist.txt", "w", encoding="utf-8") as f:
    f.write(header_whitelist + "\n")
    f.write("\n".join(sorted(cleaned_whitelist)) + "\n")

with open("cleaned_blocklist.txt", "w", encoding="utf-8") as f:
    f.write(header_blocklist + "\n")
    f.write("\n".join(sorted(cleaned_blocklist)) + "\n")

write_current_count(current_w, current_b)

# ===============================
# âœ… æ§åˆ¶å°è¾“å‡ºæ‘˜è¦
# ===============================
print("âœ… æ„å»ºå®Œæˆï¼")
print(f"ç™½åå•æ¸…ç†å: {current_w} æ¡ï¼ˆåˆ é™¤ {deleted_whitelist} æ¡ï¼‰")
print(f"é»‘åå•æ¸…ç†å: {current_b} æ¡ï¼ˆåˆ é™¤ {deleted_blocklist} æ¡ï¼‰")
print("è¾“å‡ºæ–‡ä»¶: cleaned_whitelist.txt, cleaned_blocklist.txt")
