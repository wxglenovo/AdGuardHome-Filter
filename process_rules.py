import re
import requests
import os
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor

# ===============================
# ğŸŒ ç™½åå•ä¸é»‘åå•åœ°å€
# ===============================
whitelist_url = 'https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/dist/whitelist.txt'
blocklist_url = 'https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/dist/blocklist.txt'

last_count_file = "last_count.txt"

# ===============================
# ğŸ“¥ ä¸‹è½½æ–‡ä»¶ï¼ˆå»é™¤!æˆ–#å¼€å¤´ï¼‰
# ===============================
def fetch_file(url):
    print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½: {url}")
    try:
        r = requests.get(url, timeout=15)
        r.raise_for_status()
        lines = []
        for line in r.text.splitlines():
            line = line.strip()
            if not line or line.startswith('!') or line.startswith('#'):
                continue
            lines.append(line)
        print(f"âœ… ä¸‹è½½å®Œæˆ: {url} å…± {len(lines)} è¡Œ")
        return lines
    except requests.RequestException as e:
        print(f"âŒ è·å–æ–‡ä»¶å¤±è´¥: {e}")
        exit(1)

# ===============================
# ğŸ§© æå–åŸŸåä¸åç¼€
# ===============================
def extract_domain_and_suffix(rule):
    prefix = '@@||' if rule.startswith('@@||') else '||'
    rule_body = rule[len(prefix):]
    if '^' in rule_body:
        domain, suffix = rule_body.split('^', 1)
        suffix = '^' + suffix
    else:
        domain, suffix = rule_body, ''
    return prefix, domain.strip().lower(), suffix.strip()

# ===============================
# âš™ï¸ åˆ¤æ–­å­åŸŸå…³ç³»ï¼ˆåç¼€å®Œå…¨ä¸€è‡´ï¼‰
# ===============================
def is_subdomain(sub, parent):
    return sub.endswith('.' + parent)

# ===============================
# ğŸ§¹ æ¸…ç†è§„åˆ™å‡½æ•°
# ===============================
def process_rules(rules, is_whitelist=False):
    prefix_flag = "@@||" if is_whitelist else "||"
    cleaned = []
    removed_pairs = []

    parsed = [extract_domain_and_suffix(r) for r in rules]

    for i, (prefix, domain, suffix) in enumerate(parsed):
        has_parent = False
        for j, (pprefix, pdomain, psuffix) in enumerate(parsed):
            if i == j:
                continue
            if prefix != pprefix:
                continue
            if suffix == psuffix and is_subdomain(domain, pdomain):
                has_parent = True
                removed_pairs.append((f"{prefix}{domain}{suffix}", f"{pprefix}{pdomain}{psuffix}"))
                break
        if not has_parent:
            cleaned.append(f"{prefix}{domain}{suffix}")

    print(f"\nğŸ§¹ {'ç™½åå•' if is_whitelist else 'é»‘åå•'}æ¸…ç†å®Œæˆ:")
    print(f"  åŸå§‹è§„åˆ™: {len(rules)}")
    print(f"  åˆ é™¤å­åŸŸ: {len(removed_pairs)}")
    print(f"  ä¿ç•™è§„åˆ™: {len(cleaned)}")
    if removed_pairs:
        print("ğŸ—‘ åˆ é™¤çš„åŒ¹é…é¡¹ï¼ˆå­åŸŸ â†’ çˆ¶åŸŸï¼‰:")
        for child, parent in removed_pairs[:50]:
            print(f"   âŒ {child} â†’ ä¿ç•™ {parent}")
        if len(removed_pairs) > 50:
            print(f"   â€¦â€¦ å…± {len(removed_pairs)} æ¡ï¼Œçœç•¥æ˜¾ç¤º")

    return cleaned, removed_pairs

# ===============================
# ğŸ“Š è¯»å–ä¸ä¿å­˜ä¸Šæ¬¡æ•°é‡
# ===============================
def read_last_count():
    if os.path.exists(last_count_file):
        with open(last_count_file, 'r') as f:
            lines = f.read().splitlines()
            if len(lines) >= 2:
                return int(lines[0]), int(lines[1])
    return 0, 0

def write_current_count(w_count, b_count):
    with open(last_count_file, 'w') as f:
        f.write(f"{w_count}\n{b_count}\n")

# ===============================
# ğŸ§¾ ç”Ÿæˆå¤´éƒ¨ä¿¡æ¯
# ===============================
def generate_header(list_type, original_count, deleted_count, current_count, diff, url):
    now = (datetime.utcnow() + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M:%S')
    diff_str = f"å¢åŠ  {diff} æ¡" if diff > 0 else f"å‡å°‘ {abs(diff)} æ¡" if diff < 0 else "æ— å˜åŒ– 0 æ¡"

    header = f"""###########################################################
# ğŸ“… AdGuardHome {list_type} è‡ªåŠ¨æ„å»ºä¿¡æ¯
# â° æ›´æ–°æ—¶é—´: {now} CST
# ğŸŒ æ¥æº: {url}
# --------------------------------------------------------
# åŸå§‹è§„åˆ™æ•°é‡: {original_count}
# åˆ é™¤å­åŸŸæ•°é‡: {deleted_count}
# æ¸…ç†åè§„åˆ™æ•°é‡: {current_count}
# ä¸ä¸Šæ¬¡å¯¹æ¯”: {diff_str}
# --------------------------------------------------------
# ğŸ§© è¯´æ˜:
# â–¸ çˆ¶åŸŸä¸å­åŸŸï¼ˆåç¼€å®Œå…¨ä¸€è‡´ï¼‰æ—¶ï¼Œä¿ç•™çˆ¶åŸŸè§„åˆ™ï¼Œåˆ é™¤å­åŸŸè§„åˆ™ã€‚
# â–¸ å¤šçº§å­åŸŸï¼ˆä¸‰çº§ã€å››çº§ï¼‰åˆ™ä¿ç•™çº§æ•°æ›´ä½çš„åŸŸåã€‚
# ==========================================================
"""
    return header

# ===============================
# ğŸ’¾ è¾“å‡ºç»“æœ
# ===============================
def save_result(filename, header, rules):
    with open(filename, "w", encoding="utf-8") as f:
        f.write(header + "\n")
        f.write("\n".join(sorted(rules)) + "\n")
    print(f"ğŸ’¾ å·²ç”Ÿæˆæ–‡ä»¶: {filename}")

# ===============================
# ğŸš€ ä¸»æµç¨‹
# ===============================
def main():
    # å¹¶è¡Œä¸‹è½½ç™½åå•å’Œé»‘åå•
    with ThreadPoolExecutor(max_workers=2) as executor:
        future_whitelist = executor.submit(fetch_file, whitelist_url)
        future_blocklist = executor.submit(fetch_file, blocklist_url)
        whitelist = future_whitelist.result()
        blocklist = future_blocklist.result()

    cleaned_w, removed_w = process_rules(whitelist, is_whitelist=True)
    cleaned_b, removed_b = process_rules(blocklist, is_whitelist=False)

    last_w, last_b = read_last_count()
    diff_w = len(cleaned_w) - last_w
    diff_b = len(cleaned_b) - last_b

    header_w = generate_header("ç™½åå•", len(whitelist), len(removed_w), len(cleaned_w), diff_w, whitelist_url)
    header_b = generate_header("é»‘åå•", len(blocklist), len(removed_b), len(cleaned_b), diff_b, blocklist_url)

    save_result("cleaned_whitelist.txt", header_w, cleaned_w)
    save_result("cleaned_blocklist.txt", header_b, cleaned_b)

    write_current_count(len(cleaned_w), len(cleaned_b))
    print("\nâœ… æ‰€æœ‰å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()
