import re
import requests
import os
from datetime import datetime, timedelta

# ===============================
# ğŸŒ ç™½åå•ä¸é»‘åå•åœ°å€
# ===============================
whitelist_url = 'https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/dist/whitelist.txt'
blocklist_url = 'https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/dist/blocklist.txt'

last_count_file = "last_count.txt"

# ===============================
# ğŸ“¥ è·å–è¿œç¨‹æ–‡ä»¶å¹¶æ¸…ç†æ— ç”¨è¡Œï¼ˆå»é™¤!å¼€å¤´çš„å¤´éƒ¨ä¿¡æ¯ï¼‰
# ===============================
def fetch_file(url):
    try:
        r = requests.get(url)
        r.raise_for_status()
        lines = []
        for line in r.text.splitlines():
            line = line.strip()
            if not line or line.startswith('!'):
                continue
            lines.append(line)
        return lines
    except requests.RequestException as e:
        print(f"âŒ è·å–æ–‡ä»¶å¤±è´¥: {e}")
        exit(1)

# è·å–ç™½åå•ä¸é»‘åå•è§„åˆ™
whitelist = fetch_file(whitelist_url)
blocklist = fetch_file(blocklist_url)

# ===============================
# ğŸ§© æå–ä¸»åŸŸå‡½æ•°ï¼ˆç”¨äºå»é™¤å­åŸŸï¼‰
# ===============================
def get_base_domain(domain):
    parts = domain.split('.')
    if len(parts) >= 2:
        return '.'.join(parts[-2:])  # å–åä¸¤æ®µä½œä¸ºä¸»åŸŸ
    return domain

# ===============================
# âš™ï¸ è§„åˆ™æ¸…ç†å‡½æ•°ï¼ˆåˆ é™¤å­åŸŸï¼ŒåŒºåˆ†å‰ç¼€ï¼‰
# ===============================
def process_rules(rules):
    seen = {}
    cleaned = []
    deleted_count = 0

    for line in rules:
        line = line.strip()
        if not line or line.startswith('#'):
            cleaned.append(line)
            continue

        # åŒ¹é… @@|| æˆ– || å¼€å¤´çš„è§„åˆ™
        m = re.match(r'(@@?\|\|)([^/^\$]+)(.*)', line)
        if m:
            prefix, domain, suffix = m.groups()
            base = get_base_domain(domain)
            key = (prefix, base, suffix)  # âœ… åŠ å…¥ prefix åŒºåˆ†ç™½/é»‘åå•ç±»å‹

            # åˆ¤æ–­æ˜¯å¦æ˜¯çˆ¶åŸŸ + ç›¸åŒåç¼€ï¼ˆä¾‹å¦‚ baidu.com ä¸ www.baidu.comï¼‰
            if key not in seen:
                seen[key] = line
                cleaned.append(line)
            else:
                deleted_count += 1
        else:
            cleaned.append(line)

    return cleaned, deleted_count

# ===============================
# ğŸ§¹ åˆ†åˆ«å¤„ç†ç™½åå•ä¸é»‘åå•
# ===============================
cleaned_whitelist, deleted_whitelist = process_rules(whitelist)
cleaned_blocklist, deleted_blocklist = process_rules(blocklist)

# ===============================
# ğŸ“Š è¯»å–ä¸ä¿å­˜ä¸Šæ¬¡ç»Ÿè®¡æ•°é‡
# ===============================
def read_last_count():
    if os.path.exists(last_count_file):
        with open(last_count_file, 'r') as f:
            lines = f.read().splitlines()
            if len(lines) >= 2:
                return int(lines[0]), int(lines[1])
    return 0, 0

def write_current_count(w_count, b_count):
    with open(last_count_file, 'w') as f:
        f.write(f"{w_count}\n{b_count}\n")

current_w = len(cleaned_whitelist)
current_b = len(cleaned_blocklist)
last_w, last_b = read_last_count()
diff_w = current_w - last_w
diff_b = current_b - last_b

# ===============================
# ğŸ§¾ ç”Ÿæˆå„è‡ªå¤´éƒ¨ä¿¡æ¯
# ===============================
def generate_header(list_type, original_count, deleted_count, current_count, diff, url):
    now = (datetime.utcnow() + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M:%S')  # åŒ—äº¬æ—¶é—´
    diff_str = f"å¢åŠ  {diff} æ¡" if diff > 0 else f"å‡å°‘ {abs(diff)} æ¡" if diff < 0 else "æ— å˜åŒ– 0 æ¡"

    header = f"""###########################################################
# ğŸ“… AdGuardHome {list_type} è‡ªåŠ¨æ„å»ºä¿¡æ¯
# â° æ›´æ–°æ—¶é—´: {now} CST
# ğŸŒ è§„åˆ™æ¥æº: {url}
# --------------------------------------------------------
# åŸå§‹è§„åˆ™æ•°é‡: {original_count}
# åˆ é™¤å­åŸŸæ•°é‡: {deleted_count}
# æ¸…ç†åè§„åˆ™æ•°é‡: {current_count}
# ä¸ä¸Šæ¬¡å¯¹æ¯”: {diff_str}
# --------------------------------------------------------
# ğŸ§© è¯´æ˜:
#   â–¸ å½“çˆ¶åŸŸä¸å­åŸŸï¼ˆåŒ…æ‹¬è§„åˆ™åç¼€ï¼‰åŒæ—¶å­˜åœ¨æ—¶ï¼Œä¿ç•™çˆ¶åŸŸè§„åˆ™ï¼Œåˆ é™¤å­åŸŸè§„åˆ™ã€‚
#   â–¸ å¤šçº§å­åŸŸï¼ˆä¸‰çº§ã€å››çº§ï¼‰åˆ™ä¿ç•™çº§æ•°æ›´ä½çš„åŸŸåï¼ˆçˆ¶åŸŸï¼‰ã€‚
# ==========================================================
"""
    return header

# ===============================
# ğŸ’¾ è¾“å‡ºä¸ºä¸¤ä¸ªæ–‡ä»¶
# ===============================
header_w = generate_header("ç™½åå•", len(whitelist), deleted_whitelist, current_w, diff_w, whitelist_url)
header_b = generate_header("é»‘åå•", len(blocklist), deleted_blocklist, current_b, diff_b, blocklist_url)

with open("cleaned_whitelist.txt", "w", encoding="utf-8") as f:
    f.write(header_w + "\n")
    f.write("\n".join(sorted(cleaned_whitelist)) + "\n")

with open("cleaned_blocklist.txt", "w", encoding="utf-8") as f:
    f.write(header_b + "\n")
    f.write("\n".join(sorted(cleaned_blocklist)) + "\n")

# ä¿å­˜æœ€æ–°æ•°é‡
write_current_count(current_w, current_b)

# ===============================
# âœ… æ§åˆ¶å°è¾“å‡ºæ‘˜è¦
# ===============================
print("âœ… ç™½åå•ä¸é»‘åå•å¤„ç†å®Œæˆ")
print(f"ğŸ“Š ç™½åå• åˆ é™¤å­åŸŸæ•°é‡: {deleted_whitelist}")
print(f"ğŸ“Š é»‘åå• åˆ é™¤å­åŸŸæ•°é‡: {deleted_blocklist}")
print("ğŸ“„ å·²è¾“å‡ºæ–‡ä»¶: cleaned_whitelist.txt ä¸ cleaned_blocklist.txt")
