#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
import requests
from datetime import datetime
from urllib.parse import urlparse

# ==========================================================
# ğŸ“Œ è§„åˆ™æ¥æº
# ==========================================================
whitelist_url = 'https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/dist/whitelist.txt'
blocklist_url = 'https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/dist/blocklist.txt'

# ==========================================================
# ğŸ“Œ ä¸‹è½½è§„åˆ™æ–‡ä»¶
# ==========================================================
def download_rules(url):
    resp = requests.get(url, timeout=60)
    resp.encoding = 'utf-8'
    lines = [line.strip() for line in resp.text.splitlines() if line.strip()]
    return lines

# ==========================================================
# ğŸ“Œ æå–åŸŸåä¸è§„åˆ™åç¼€
# ==========================================================
def extract_domain_and_suffix(rule):
    match = re.match(r'(@@)?\|\|([^/^$]+)(.*)', rule)
    if match:
        prefix = match.group(1) or ''
        domain = match.group(2).strip('.')
        suffix = match.group(3)
        return prefix, domain, suffix
    return '', '', ''

# ==========================================================
# ğŸ“Œ åˆ¤æ–­æ˜¯å¦ä¸ºå­åŸŸ
# ==========================================================
def is_subdomain(child, parent):
    return child.endswith('.' + parent)

# ==========================================================
# ğŸ“Œ æ¸…ç†é€»è¾‘
# ==========================================================
def clean_rules(rules):
    parsed = []
    for rule in rules:
        prefix, domain, suffix = extract_domain_and_suffix(rule)
        if domain:
            parsed.append((prefix, domain, suffix, rule))

    cleaned = []
    domains = sorted(parsed, key=lambda x: x[1].count('.'))  # æŒ‰çº§æ•°ä»ä½åˆ°é«˜

    skip = set()
    for i, (prefix_i, domain_i, suffix_i, rule_i) in enumerate(domains):
        if rule_i in skip:
            continue
        for j, (prefix_j, domain_j, suffix_j, rule_j) in enumerate(domains):
            if i != j and rule_j not in skip:
                if is_subdomain(domain_j, domain_i) and suffix_i == suffix_j and prefix_i == prefix_j:
                    skip.add(rule_j)
    for prefix, domain, suffix, rule in domains:
        if rule not in skip:
            cleaned.append(rule)

    return cleaned, len(skip)

# ==========================================================
# ğŸ“Œ è¾“å‡ºå¤´éƒ¨ä¿¡æ¯
# ==========================================================
def build_header(stats):
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S CST")
    header = f"""###########################################################
# ğŸ“… AdGuardHome ç»¼åˆè§„åˆ™è‡ªåŠ¨æ„å»ºä¿¡æ¯
# â° æ›´æ–°æ—¶é—´: {now}
# ğŸŒ è§„åˆ™æ¥æº:
#   ç™½åå•: {whitelist_url}
#   é»‘åå•: {blocklist_url}
# --------------------------------------------------------
# ğŸ“Š ç™½åå•ç»Ÿè®¡:
#   â–¸ åŸå§‹è§„åˆ™æ•°é‡: {stats['white_total']}
#   â–¸ åˆ é™¤å­åŸŸæ•°é‡: {stats['white_removed']}
#   â–¸ æ¸…ç†åè§„åˆ™æ•°é‡: {stats['white_final']}
# --------------------------------------------------------
# ğŸ“Š é»‘åå•ç»Ÿè®¡:
#   â–¸ åŸå§‹è§„åˆ™æ•°é‡: {stats['black_total']}
#   â–¸ åˆ é™¤å­åŸŸæ•°é‡: {stats['black_removed']}
#   â–¸ æ¸…ç†åè§„åˆ™æ•°é‡: {stats['black_final']}
# --------------------------------------------------------
# ğŸ§© è§„åˆ™å¤„ç†é€»è¾‘è¯´æ˜:
#   1ï¸âƒ£ å½“çˆ¶åŸŸä¸å­åŸŸï¼ˆåŒ…æ‹¬è§„åˆ™åç¼€ï¼‰åŒæ—¶å­˜åœ¨æ—¶ï¼Œä¿ç•™çˆ¶åŸŸè§„åˆ™ï¼Œåˆ é™¤å­åŸŸè§„åˆ™ã€‚
#   2ï¸âƒ£ å¤šçº§å­åŸŸï¼ˆå¦‚ä¸‰çº§ã€å››çº§ï¼‰åˆ™ä¿ç•™çº§æ•°æ›´ä½çš„åŸŸåï¼ˆçˆ¶åŸŸï¼‰ã€‚
#   3ï¸âƒ£ è‹¥æ— åŒ¹é…å­åŸŸï¼Œä»…ä¿ç•™ä¸»è§„åˆ™ï¼ˆå¦‚ @@||baidu.com^*&cb=BaiduSuggestionï¼‰ã€‚
# ==========================================================
! =====================
! ğŸ”° AdGuardHome ç»¼åˆè§„åˆ™å¼€å§‹
! =====================
"""
    return header

# ==========================================================
# ğŸ“Œ ä¸»æ‰§è¡Œé€»è¾‘
# ==========================================================
def main():
    print("ğŸ“¥ å¼€å§‹ä¸‹è½½è§„åˆ™æ–‡ä»¶...")
    whitelist = download_rules(whitelist_url)
    blocklist = download_rules(blocklist_url)

    print("ğŸ§¹ å¼€å§‹æ¸…ç†ç™½åå•è§„åˆ™...")
    cleaned_white, removed_white = clean_rules(whitelist)

    print("ğŸ§¹ å¼€å§‹æ¸…ç†é»‘åå•è§„åˆ™...")
    cleaned_black, removed_black = clean_rules(blocklist)

    stats = {
        "white_total": len(whitelist),
        "white_removed": removed_white,
        "white_final": len(cleaned_white),
        "black_total": len(blocklist),
        "black_removed": removed_black,
        "black_final": len(cleaned_black),
    }

    header = build_header(stats)
    output = header + "\n".join(cleaned_white + cleaned_black)

    with open("AdGuardHome_Filter.txt", "w", encoding="utf-8") as f:
        f.write(output)

    print("âœ… æ„å»ºå®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶ï¼šAdGuardHome_Filter.txt")

# ==========================================================
if __name__ == "__main__":
    main()
