
import re
import requests
from datetime import datetime

# ==========================================================
# ğŸ“Œ è§„åˆ™æ¥æº
# ==========================================================
whitelist_url = 'https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/dist/whitelist.txt'
blocklist_url = 'https://raw.githubusercontent.com/wxglenovo/AdGuardHome-Filter/refs/heads/main/dist/blocklist.txt'

# ==========================================================
# ğŸ“Œ ä¸‹è½½è§„åˆ™æ–‡ä»¶
# ==========================================================
def download_rules(url):
    print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½: {url}")
    resp = requests.get(url, timeout=60)
    resp.encoding = 'utf-8'
    lines = [line.strip() for line in resp.text.splitlines() if line.strip()]
    return lines

# ==========================================================
# ğŸ“Œ æå–åŸŸåä¸è§„åˆ™åç¼€
# ==========================================================
def extract_domain_and_suffix(rule):
    match = re.match(r'(@@)?\|\|([^/^$]+)(.*)', rule)
    if match:
        prefix = match.group(1) or ''
        domain = match.group(2).strip('.')
        suffix = match.group(3)
        return prefix, domain, suffix
    return '', '', ''

# ==========================================================
# ğŸ“Œ åˆ¤æ–­æ˜¯å¦ä¸ºå­åŸŸ
# ==========================================================
def is_subdomain(child, parent):
    return child.endswith('.' + parent)

# ==========================================================
# ğŸ“Œ æ¸…ç†é€»è¾‘ï¼šåˆ é™¤çˆ¶åŸŸ + å­åŸŸé‡å¤é¡¹
# ==========================================================
def clean_rules(rules):
    parsed = []
    for rule in rules:
        prefix, domain, suffix = extract_domain_and_suffix(rule)
        if domain:
            parsed.append((prefix, domain, suffix, rule))

    # æŒ‰åŸŸåçº§æ•°æ’åºï¼ˆä½çº§åœ¨å‰ï¼‰
    parsed.sort(key=lambda x: x[1].count('.'))
    skip = set()

    for i, (prefix_i, domain_i, suffix_i, rule_i) in enumerate(parsed):
        if rule_i in skip:
            continue
        for j, (prefix_j, domain_j, suffix_j, rule_j) in enumerate(parsed):
            if i != j and rule_j not in skip:
                # åˆ é™¤å­åŸŸï¼ˆå‰ç¼€å’Œåç¼€å®Œå…¨ä¸€è‡´æ—¶ï¼‰
                if is_subdomain(domain_j, domain_i) and suffix_i == suffix_j and prefix_i == prefix_j:
                    skip.add(rule_j)

    cleaned = [rule for _, _, _, rule in parsed if rule not in skip]
    return cleaned, len(skip)

# ==========================================================
# ğŸ“Œ ç”Ÿæˆå¤´éƒ¨ä¿¡æ¯ï¼ˆæ—  â€œ!â€ å†…å®¹ï¼‰
# ==========================================================
def build_header(stats):
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S CST")
    header = f"""###########################################################
# ğŸ“… AdGuardHome ç»¼åˆè§„åˆ™è‡ªåŠ¨æ„å»ºä¿¡æ¯
# â° æ›´æ–°æ—¶é—´: {now}
# ğŸŒ è§„åˆ™æ¥æº:
#   ç™½åå•: {whitelist_url}
#   é»‘åå•: {blocklist_url}
# --------------------------------------------------------
# ç™½åå•åŸå§‹è§„åˆ™æ•°é‡: {stats['white_total']}
# ç™½åå•åˆ é™¤å­åŸŸæ•°é‡: {stats['white_removed']}
# ç™½åå•æ¸…ç†åè§„åˆ™æ•°é‡: {stats['white_final']}
# --------------------------------------------------------
# é»‘åå•åŸå§‹è§„åˆ™æ•°é‡: {stats['black_total']}
# é»‘åå•åˆ é™¤å­åŸŸæ•°é‡: {stats['black_removed']}
# é»‘åå•æ¸…ç†åè§„åˆ™æ•°é‡: {stats['black_final']}
# --------------------------------------------------------
# è¯´æ˜:
#   å½“çˆ¶åŸŸä¸å­åŸŸï¼ˆåŒ…æ‹¬è§„åˆ™åç¼€ï¼‰åŒæ—¶å­˜åœ¨æ—¶ï¼Œä¿ç•™çˆ¶åŸŸè§„åˆ™ï¼Œåˆ é™¤å­åŸŸè§„åˆ™ã€‚
#   å¤šçº§å­åŸŸï¼ˆä¸‰çº§ã€å››çº§ï¼‰åˆ™ä¿ç•™çº§æ•°æ›´ä½çš„åŸŸåï¼ˆçˆ¶åŸŸï¼‰ã€‚
# ==========================================================
"""
    return header

# ==========================================================
# ğŸ“Œ ä¸»æ‰§è¡Œé€»è¾‘
# ==========================================================
def main():
    print("ğŸ“¥ å¼€å§‹ä¸‹è½½è§„åˆ™æ–‡ä»¶...")
    whitelist = download_rules(whitelist_url)
    blocklist = download_rules(blocklist_url)

    print("ğŸ§¹ æ¸…ç†ç™½åå•...")
    cleaned_white, removed_white = clean_rules(whitelist)

    print("ğŸ§¹ æ¸…ç†é»‘åå•...")
    cleaned_black, removed_black = clean_rules(blocklist)

    stats = {
        "white_total": len(whitelist),
        "white_removed": removed_white,
        "white_final": len(cleaned_white),
        "black_total": len(blocklist),
        "black_removed": removed_black,
        "black_final": len(cleaned_black),
    }

    header = build_header(stats)
    all_rules = cleaned_white + cleaned_black
    output = header + "\n".join(all_rules) + "\n"

    with open("AdGuardHome_Filter.txt", "w", encoding="utf-8") as f:
        f.write(output)

    print("âœ… è§„åˆ™æ„å»ºå®Œæˆ â†’ AdGuardHome_Filter.txt")

# ==========================================================
if __name__ == "__main__":
    main()
