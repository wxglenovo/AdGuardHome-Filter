#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import dns.resolver
import concurrent.futures
import os
import sys

URLS_FILE = "urls.txt"
OUTPUT_DIR = "dist"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "blocklist_valid.txt")
LOG_FILE = os.path.join(OUTPUT_DIR, "deleted_rules.log")
MAX_WORKERS = 30  # å¹¶è¡Œçº¿ç¨‹æ•°ï¼Œå¯æŒ‰æ€§èƒ½è°ƒæ•´

def fetch_rules(url):
    """ä¸‹è½½å•ä¸ªè§„åˆ™æ–‡ä»¶"""
    try:
        print(f"â¬‡ï¸ æ­£åœ¨ä¸‹è½½: {url}")
        resp = requests.get(url, timeout=20)
        resp.raise_for_status()
        return resp.text.splitlines()
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {url} - {e}")
        return []

def is_valid_domain(domain: str) -> bool:
    """æ£€æŸ¥åŸŸåæ˜¯å¦å¯è§£æ"""
    try:
        dns.resolver.resolve(domain, 'A')
        return True
    except Exception:
        return False

def clean_domain(line: str) -> str:
    """ä»è§„åˆ™ä¸­æå–åŸŸå"""
    domain = line.lstrip('|').lstrip('.')
    domain = domain.split('^')[0]
    return domain.strip()

def check_rule(line: str) -> str | None:
    """æ£€æŸ¥å•æ¡è§„åˆ™æœ‰æ•ˆæ€§"""
    line = line.strip()
    if not line or line.startswith('#'):
        return line  # ä¿ç•™æ³¨é‡Šå’Œç©ºè¡Œ
    if line.startswith(('||', '|', '.')):
        if '*' in line or '$' in line or '/' in line:
            return line
        domain = clean_domain(line)
        if is_valid_domain(domain):
            return line
        else:
            print(f"âš ï¸ åˆ é™¤æ— æ•ˆè§„åˆ™: {line}")
            return None
    return line

def main():
    print("ğŸ“˜ è¯»å– urls.txt ...")
    if not os.path.exists(URLS_FILE):
        print("âŒ æœªæ‰¾åˆ° urls.txt")
        sys.exit(1)

    with open(URLS_FILE, "r", encoding="utf-8") as f:
        urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]

    # ä¸‹è½½ä¸åˆå¹¶è§„åˆ™
    print(f"ğŸŒ å…± {len(urls)} ä¸ªè§„åˆ™æºï¼Œå¼€å§‹ä¸‹è½½...")
    all_rules = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        results = executor.map(fetch_rules, urls)
        for lines in results:
            all_rules.extend(lines)

    print(f"ğŸ§¹ åˆå¹¶å‰è§„åˆ™æ€»æ•°: {len(all_rules)}")
    all_rules = list(dict.fromkeys(all_rules))  # å»é‡
    print(f"âœ… å»é‡åè§„åˆ™æ€»æ•°: {len(all_rules)}")

    # æ£€æŸ¥åŸŸåæœ‰æ•ˆæ€§
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    valid_rules = []
    deleted_rules = []

    print("ğŸ” å¼€å§‹æ£€æµ‹è§„åˆ™æœ‰æ•ˆæ€§...")
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        results = list(executor.map(check_rule, all_rules))

    for original, result in zip(all_rules, results):
        if result:
            valid_rules.append(result)
        else:
            deleted_rules.append(original)

    # è¾“å‡ºç»“æœ
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write('\n'.join(valid_rules))
    print(f"âœ… æœ‰æ•ˆè§„åˆ™å·²ä¿å­˜è‡³: {OUTPUT_FILE}")

    if deleted_rules:
        with open(LOG_FILE, "w", encoding="utf-8") as f:
            f.write('\n'.join(deleted_rules))
        print(f"ğŸ“ è¢«åˆ é™¤è§„åˆ™æ—¥å¿—å·²ä¿å­˜: {LOG_FILE} (å…± {len(deleted_rules)} æ¡)")

if __name__ == "__main__":
    main()
